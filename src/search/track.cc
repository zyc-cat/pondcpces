#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <time.h>
#include "solve.h"
#include "graph.h"
#include "lao.h"
#include "vi.h"
#include "backup.h"

/* The racetrack input file is generated by a pearl script called
   build.pl which is run on a map of the track.

   Format for racetrack input file:
     first line: 
         total number of states
     discount factor
     second line: 
         list of start states (equal probability of starting in each)
     subsequent lines: 
         state index
     state description
     action index
     0 if regular state, 1 if GOAL, 2 if WALL
     (goal probability -- not used, is 1.0 for GOAL, otherwise 0.0)
     next state if action succeeeds
     next state if action fails

   After generating input file using pearl script, make the following
   changes: 
    -- add the first two lines
    -- change terminal value for WALL from 1 to 2 so that the wall 
       can be distinguished from the goal state.

   Note that hitting the wall causes a transition to a start state.

   The start state (-1) and wall state have zero cost transition to
   uniform probability distribution over possible start states.
*/

void readRacetrackMDP(){
  FILE*                     file;
  char                      description[15];
  char                      str[30]; /* for reading lines of input file */
  int                       state, action, nextStateSuccess, nextStateFail,
                            numFields, terminal, start[6], i;
  float                     goalProb;
  struct StateNode*         stateNode;
  struct ActionNode*        actionNode;
  struct StateDistribution* Distribution;

  file = fopen(gInputFileName, "r");
  if(file == NULL){
    printf("Data file %s not found!\n", gInputFileName);
    exit(1);
  }

  fgets(str, 100, file); 
  sscanf(str, "%d %lf", &gNumStates, &gDiscount); 
  gNumActions = 9;  /* racetrack problem has 9 actions */

  /* allocate vector of state nodes */
  StateIndex = (struct StateNode**)malloc((unsigned)gNumStates*sizeof(struct StateNode*));
  for(state = 0; state < gNumStates; state++){
    StateIndex[state] = new StateNode();
    StateIndex[state]->StateNo = state;
    /* also allocate memory for state description */
    StateIndex[state]->Description = (char*)malloc(15*sizeof(char));
    /* set initial action lists to NULL */
    StateIndex[state]->NextActions = NULL;
    StateIndex[state]->PrevActions = NULL;
    /* Initial heuristic cost-to-go is zero */
    StateIndex[state]->f = 0.0;
  }

  /* build start state */
  fgets(str, 100, file); 
  numFields = sscanf(str, "%d %d %d %d %d %d", &start[0], &start[1], &start[2], &start[3], &start[4], &start[5]);

  Start = new StateNode();
  Start->StateNo = -1;
  Start->Description = "START";
  Start->f = 0.0;
  Start->Terminal = 0;
  Start->Expanded = 0;
  Start->NextActions = new ActionNodeList;
  Start->NextActions->push_back(Start->BestAction = new ActionNode());
  Start->BestAction->ActionNo = -1;
  Start->BestAction->Cost = 0.0;
  Start->BestAction->PrevState = Start;
  Start->BestAction->NextState = CreateStateDistribution();

  Distribution = Start->NextActions->front()->NextState;
  Distribution->State = StateIndex[start[0]];
  Distribution->Prob = 1.0 / numFields;

  StateIndex[start[0]]->PrevActions = new ActionNodeList;
  StateIndex[start[0]]->PrevActions->push_back(Start->BestAction);

  for(i = 1; i < numFields; i++){
    Distribution->Next = CreateStateDistribution();
    Distribution = Distribution->Next;
    Distribution->State = StateIndex[start[i]];
    Distribution->Prob = 1.0 / numFields;
    StateIndex[start[i]]->PrevActions = new ActionNodeList;
    StateIndex[start[i]]->PrevActions->push_back(Start->BestAction);
  }

  Distribution->Next = NULL;
  
  /* each input line begins with state number and contains 
     transition probs for a state-action pair */
  while(!feof(file)){
    fgets(str, 100, file); 
    numFields = sscanf(str, "%d %s %d %d %f %d %d",
       &state,
       description,
       &action,
       &terminal,
       &goalProb,
       &nextStateSuccess,
       &nextStateFail);
    stateNode = StateIndex[state];
    strncpy(stateNode->Description, description, 15);
    stateNode->Terminal = terminal;

    /* Only non-terminal states have next states. In a non-terminal 
       state, every action has two next states and a cost of 1.0. */
    if(stateNode->Terminal == 0){
      /* allocate memory for action and add to list of actions */
      actionNode = new ActionNode();
      actionNode->ActionNo = action;

      /* insert new action node at end of list */
      stateNode->NextActions->push_back(actionNode);

      /* create best action is it doesn't already exist */
      if(stateNode->BestAction == NULL)
        stateNode->BestAction = actionNode;

      /* Allocate memory for next state distributions */
      actionNode->NextState = CreateStateDistribution();
      actionNode->NextState->State = StateIndex[nextStateSuccess];

      /* Also add pointers from next states back to this action. */
      StateIndex[nextStateSuccess]->PrevActions->push_back(actionNode);

      if(numFields == 7){   /* 2 possible next states */
        /* actions have intended effect with probability 0.9 */
        actionNode->NextState->Prob = 0.9;
        actionNode->NextState->Next = CreateStateDistribution();
        actionNode->NextState->Next->State = StateIndex[nextStateFail];
        actionNode->NextState->Next->Prob = 0.1;
        actionNode->NextState->Next->Next = NULL;

        /* Also add pointer from next states back to this action. */
        StateIndex[nextStateFail]->PrevActions->push_back(actionNode);
      }
      else{ /* 1 possible next state */
        actionNode->NextState->Prob = 1.0;
        actionNode->NextState->Next = NULL;
      }

      /* cost of every action is 1.0 */
      actionNode->Cost = 1.0;

      /* pointer to state in which action is taken */
      actionNode->PrevState = stateNode;
    }
    else if(stateNode->Terminal == 1){
      stateNode->f = 0.0;
      Goal = stateNode;
    }
    else if(stateNode->Terminal == 2){  /* wall */
      stateNode->f = 0.0;
      stateNode->NextActions = new ActionNodeList;
      stateNode->NextActions->push_back(stateNode->BestAction = new ActionNode());
      stateNode->BestAction->ActionNo = -1;
      stateNode->BestAction->Cost = 0.0;
      stateNode->BestAction->PrevState = stateNode;
      stateNode->BestAction->NextState = 
      Start->NextActions->front()->NextState;
      /* make WALL parent of START */
      Start->PrevActions = stateNode->NextActions;
    }
  }
  fclose(file);
}

/****** This doesn't yet work correctly for discounted MDPs ******/
void CreateHeuristic(){
  StateList *CurrentList, *NewList;
  StateList::iterator node;
  ActionNodeList::iterator prev;

  CurrentList = new StateList;

  /* Initial CurrentList contains GOAL */
  Goal->h = 0.0;
  Goal->g = 0.0;
  Goal->f = 0.0;
  Goal->fWeight = 0.0;
  CurrentList->push_back(Goal);

  /* Add unvisited states that can be reached by one backward step */
  while(!CurrentList->empty()){ /* check for empty list */
    NewList = new StateList;
    /* For each state added in previous step ... */
    for(node = CurrentList->begin(); node != CurrentList->end(); node++){
      /* ... and for each parent of that state ... */
      for(prev = (*node)->PrevActions->begin(); prev != (*node)->PrevActions->end(); prev++){
        ActionNode *prevAct = *prev;

        /* If parent has not already been updated, update heuristic and add to list */
        if(prevAct->PrevState->h == 0.0){
          prevAct->PrevState->f =
              prevAct->PrevState->h = 
                  gDiscount * (*node)->h + prevAct->Cost;
          prevAct->PrevState->g = 0.0;
          prevAct->PrevState->fWeight = gWeight * prevAct->PrevState->f;
          NewList->push_back(prevAct->PrevState);
        }
      }
    }

    delete CurrentList;
    CurrentList = NewList;
    NewList = NULL;
  }

  delete CurrentList;
}

void initMeanFirstPassage(){
  int state;

  for(state = 0; state < gNumStates; state++)
    if(StateIndex[state]->Terminal == 1)
      StateIndex[state]->meanFirstPassage = 0.0;
    else
      StateIndex[state]->meanFirstPassage = 200.0;
}
